{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c062a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "266e6c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training.1600000.processed.noemoticon.csv',\n",
    "                encoding=\"latin\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79955e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0           1                             2         3                4  \\\n",
       "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                                   5  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2  @Kenichan I dived many times for the ball. Man...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a156744",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"target\", \"id\", \"date\", \"flag\", \"user\", \"tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bed4f34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                              tweet  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acf22f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6464225c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    800000\n",
       "4    800000\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "239ec764",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['id', 'date', 'flag', 'user'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75ddb866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                              tweet\n",
       "0             0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1             0  is upset that he can't update his Facebook by ...\n",
       "2             0  @Kenichan I dived many times for the ball. Man...\n",
       "3             0    my whole body feels itchy and like its on fire \n",
       "4             0  @nationwideclass no, it's not behaving at all....\n",
       "...         ...                                                ...\n",
       "1599995       4  Just woke up. Having no school is the best fee...\n",
       "1599996       4  TheWDB.com - Very cool to hear old Walt interv...\n",
       "1599997       4  Are you ready for your MoJo Makeover? Ask me f...\n",
       "1599998       4  Happy 38th Birthday to my boo of alll time!!! ...\n",
       "1599999       4  happy #charitytuesday @theNSPCC @SparksCharity...\n",
       "\n",
       "[1600000 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a463c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                              tweet\n",
       "0       0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1       0  is upset that he can't update his Facebook by ...\n",
       "2       0  @Kenichan I dived many times for the ball. Man...\n",
       "3       0    my whole body feels itchy and like its on fire \n",
       "4       0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "312e5e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"@blabers no, sorry, it's fabber cos we have the good weather AND electricity! \",\n",
       " 'Why is it that I have 46 followers, none of whom acknowledge me? ',\n",
       " \"Cold beer and a month's worth of time recording, lazy Sunday afternoon \",\n",
       " \"@yenymt no not slow just mimi times, resting from a very busy day...i don't have buddies to drink with \",\n",
       " 'i want to leave for England sooner. can i, can i?? probably not ',\n",
       " 'Lovely weather again today bloody rain what happened to the lush sunshine!?! anyway home from work blah now time for a cup o coffee  hehe',\n",
       " 'Oh no, they have to give me a shot....lawed help me ',\n",
       " 'Leaving nyc and @ghosthawkx ',\n",
       " \"Currently cleaning my makeup brushes after massive guilt trip that I don't take good care of them \",\n",
       " 'ï¿½s wishing it was nightime+ that she war makn her way to Herbal ']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)['tweet'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcccda61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   target  1600000 non-null  int64 \n",
      " 1   tweet   1600000 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 24.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edd9804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].replace(4,1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "295231f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    800000\n",
       "1    800000\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a38a2fa",
   "metadata": {},
   "source": [
    "# Nettoyage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71d6246d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/kevin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34545f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6d3bea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4750f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cool cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8975be41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bonjour'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"         bonjour        \".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5eafe2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47c60434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e3cb6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27340e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nettoyage(text):\n",
    "    to_remove = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "    text = re.sub(to_remove, \" \", str(text).lower().strip())\n",
    "    tokens = []\n",
    "    \n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            token = stemmer.stem(token)\n",
    "            tokens.append(token)\n",
    "            \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f7b70694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'35 more minutes. I need a time machine! Waiting is not fun '"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(1)['tweet'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8df75ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'35 minut need time machin wait fun'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nettoyage(\"35 more minutes. I need a time machine! Waiting is not fun \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ccfd65e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"tweet\"].apply(nettoyage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ceba7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339919         well 21 idea happen last night wish mikeyshim\n",
       "1390669    one local suburb dont know wifi wifi anyway ca...\n",
       "1323213    go school afternoon 45 minut exam get bus back...\n",
       "701309                                     eez hayley follow\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"].sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08688af",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "073a6b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d020d9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6ef669da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280000, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e902dfc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320000, 3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0387b5bb",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b210f32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "16986616",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e2cf5bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "??tokenizer.fit_on_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "96bc86c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.text.Tokenizer at 0x7f280fc25210>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e8b9417",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8dda5ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>tweet</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1374558</th>\n",
       "      <td>1</td>\n",
       "      <td>@jbtaylor WIth ya. &amp;quot;I'd like a Palm Pre, ...</td>\n",
       "      <td>ya quot like palm pre touchston charger readyn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389115</th>\n",
       "      <td>1</td>\n",
       "      <td>felt the earthquake this afternoon, it seems t...</td>\n",
       "      <td>felt earthquak afternoon seem epicent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137831</th>\n",
       "      <td>1</td>\n",
       "      <td>Ruffles on shirts are like so in, me Likey</td>\n",
       "      <td>ruffl shirt like likey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790714</th>\n",
       "      <td>0</td>\n",
       "      <td>Pretty bad night into a crappy morning....FML!...</td>\n",
       "      <td>pretti bad night crappi morn fml buttfac didnt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117911</th>\n",
       "      <td>1</td>\n",
       "      <td>@dcbriccetti yeah, what a clear view!</td>\n",
       "      <td>yeah clear view</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                              tweet  \\\n",
       "1374558       1  @jbtaylor WIth ya. &quot;I'd like a Palm Pre, ...   \n",
       "1389115       1  felt the earthquake this afternoon, it seems t...   \n",
       "1137831       1        Ruffles on shirts are like so in, me Likey    \n",
       "790714        0  Pretty bad night into a crappy morning....FML!...   \n",
       "1117911       1             @dcbriccetti yeah, what a clear view!    \n",
       "\n",
       "                                                      text  \n",
       "1374558  ya quot like palm pre touchston charger readyn...  \n",
       "1389115              felt earthquak afternoon seem epicent  \n",
       "1137831                             ruffl shirt like likey  \n",
       "790714   pretti bad night crappi morn fml buttfac didnt...  \n",
       "1117911                                    yeah clear view  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "15838c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'go': 1,\n",
       " 'get': 2,\n",
       " 'day': 3,\n",
       " 'good': 4,\n",
       " 'work': 5,\n",
       " 'like': 6,\n",
       " 'love': 7,\n",
       " 'quot': 8,\n",
       " 'today': 9,\n",
       " 'time': 10,\n",
       " 'got': 11,\n",
       " 'thank': 12,\n",
       " 'lol': 13,\n",
       " 'one': 14,\n",
       " 'want': 15,\n",
       " 'back': 16,\n",
       " 'miss': 17,\n",
       " 'u': 18,\n",
       " 'know': 19,\n",
       " 'see': 20,\n",
       " 'think': 21,\n",
       " 'feel': 22,\n",
       " 'im': 23,\n",
       " 'realli': 24,\n",
       " 'amp': 25,\n",
       " 'night': 26,\n",
       " 'hope': 27,\n",
       " 'watch': 28,\n",
       " 'still': 29,\n",
       " 'need': 30,\n",
       " 'make': 31,\n",
       " 'well': 32,\n",
       " '2': 33,\n",
       " 'new': 34,\n",
       " 'home': 35,\n",
       " 'oh': 36,\n",
       " 'look': 37,\n",
       " 'come': 38,\n",
       " 'much': 39,\n",
       " 'last': 40,\n",
       " 'twitter': 41,\n",
       " 'morn': 42,\n",
       " 'tomorrow': 43,\n",
       " 'wish': 44,\n",
       " 'great': 45,\n",
       " 'sad': 46,\n",
       " 'sleep': 47,\n",
       " '3': 48,\n",
       " 'wait': 49,\n",
       " 'haha': 50,\n",
       " 'fun': 51,\n",
       " 'bad': 52,\n",
       " 'week': 53,\n",
       " 'tri': 54,\n",
       " 'follow': 55,\n",
       " 'right': 56,\n",
       " 'happi': 57,\n",
       " 'would': 58,\n",
       " 'thing': 59,\n",
       " 'friend': 60,\n",
       " 'sorri': 61,\n",
       " 'tonight': 62,\n",
       " 'say': 63,\n",
       " 'way': 64,\n",
       " 'take': 65,\n",
       " 'though': 66,\n",
       " 'gonna': 67,\n",
       " 'nice': 68,\n",
       " 'better': 69,\n",
       " 'hate': 70,\n",
       " 'even': 71,\n",
       " 'yeah': 72,\n",
       " 'bed': 73,\n",
       " 'tweet': 74,\n",
       " 'could': 75,\n",
       " 'start': 76,\n",
       " 'school': 77,\n",
       " 'peopl': 78,\n",
       " 'hour': 79,\n",
       " 'show': 80,\n",
       " 'play': 81,\n",
       " 'guy': 82,\n",
       " 'weekend': 83,\n",
       " 'hey': 84,\n",
       " 'final': 85,\n",
       " '4': 86,\n",
       " 'awesom': 87,\n",
       " 'yes': 88,\n",
       " 'next': 89,\n",
       " 'let': 90,\n",
       " 'use': 91,\n",
       " 'lt': 92,\n",
       " 'dont': 93,\n",
       " 'never': 94,\n",
       " 'soon': 95,\n",
       " 'cant': 96,\n",
       " 'tire': 97,\n",
       " 'rain': 98,\n",
       " 'long': 99,\n",
       " 'pleas': 100,\n",
       " 'littl': 101,\n",
       " 'first': 102,\n",
       " 'everyon': 103,\n",
       " 'year': 104,\n",
       " 'wanna': 105,\n",
       " 'movi': 106,\n",
       " 'life': 107,\n",
       " 'best': 108,\n",
       " 'sick': 109,\n",
       " 'ok': 110,\n",
       " 'girl': 111,\n",
       " 'find': 112,\n",
       " 'call': 113,\n",
       " 'suck': 114,\n",
       " 'bore': 115,\n",
       " 'sure': 116,\n",
       " 'done': 117,\n",
       " 'head': 118,\n",
       " 'help': 119,\n",
       " '1': 120,\n",
       " 'alway': 121,\n",
       " 'talk': 122,\n",
       " 'x': 123,\n",
       " 'keep': 124,\n",
       " 'alreadi': 125,\n",
       " 'cool': 126,\n",
       " 'anoth': 127,\n",
       " 'lot': 128,\n",
       " 'someth': 129,\n",
       " 'us': 130,\n",
       " 'eat': 131,\n",
       " 'live': 132,\n",
       " 'man': 133,\n",
       " 'phone': 134,\n",
       " 'leav': 135,\n",
       " 'hurt': 136,\n",
       " 'readi': 137,\n",
       " 'read': 138,\n",
       " 'made': 139,\n",
       " 'yay': 140,\n",
       " 'enjoy': 141,\n",
       " 'yet': 142,\n",
       " 'hous': 143,\n",
       " 'went': 144,\n",
       " 'song': 145,\n",
       " 'ur': 146,\n",
       " 'sound': 147,\n",
       " 'thought': 148,\n",
       " 'ever': 149,\n",
       " 'pretti': 150,\n",
       " 'mayb': 151,\n",
       " 'amaz': 152,\n",
       " 'excit': 153,\n",
       " 'summer': 154,\n",
       " 'n': 155,\n",
       " 'finish': 156,\n",
       " 'away': 157,\n",
       " 'omg': 158,\n",
       " 'guess': 159,\n",
       " 'old': 160,\n",
       " 'game': 161,\n",
       " 'tell': 162,\n",
       " 'damn': 163,\n",
       " 'mean': 164,\n",
       " '5': 165,\n",
       " 'earli': 166,\n",
       " 'someon': 167,\n",
       " 'listen': 168,\n",
       " 'check': 169,\n",
       " 'babi': 170,\n",
       " 'bit': 171,\n",
       " 'left': 172,\n",
       " 'lost': 173,\n",
       " 'give': 174,\n",
       " 'wow': 175,\n",
       " 'parti': 176,\n",
       " 'big': 177,\n",
       " 'late': 178,\n",
       " 'end': 179,\n",
       " 'hear': 180,\n",
       " 'noth': 181,\n",
       " 'hot': 182,\n",
       " 'ya': 183,\n",
       " 'birthday': 184,\n",
       " 'glad': 185,\n",
       " 'hard': 186,\n",
       " 'actual': 187,\n",
       " 'happen': 188,\n",
       " 'pic': 189,\n",
       " 'also': 190,\n",
       " 'stop': 191,\n",
       " 'sun': 192,\n",
       " 'later': 193,\n",
       " 'weather': 194,\n",
       " 'two': 195,\n",
       " 'mom': 196,\n",
       " 'stuff': 197,\n",
       " 'w': 198,\n",
       " 'wonder': 199,\n",
       " 'put': 200,\n",
       " 'ugh': 201,\n",
       " 'saw': 202,\n",
       " 'run': 203,\n",
       " 'fuck': 204,\n",
       " 'god': 205,\n",
       " 'car': 206,\n",
       " 'might': 207,\n",
       " 'exam': 208,\n",
       " 'stay': 209,\n",
       " 'world': 210,\n",
       " 'yesterday': 211,\n",
       " 'music': 212,\n",
       " 'that': 213,\n",
       " 'kid': 214,\n",
       " 'said': 215,\n",
       " 'meet': 216,\n",
       " 'sinc': 217,\n",
       " 'job': 218,\n",
       " 'hi': 219,\n",
       " 'post': 220,\n",
       " 'gotta': 221,\n",
       " 'updat': 222,\n",
       " 'beauti': 223,\n",
       " 'friday': 224,\n",
       " 'monday': 225,\n",
       " 'sunday': 226,\n",
       " 'around': 227,\n",
       " 'mani': 228,\n",
       " 'video': 229,\n",
       " 'seem': 230,\n",
       " 'b': 231,\n",
       " 'luck': 232,\n",
       " 'cold': 233,\n",
       " 'found': 234,\n",
       " 'cri': 235,\n",
       " 'poor': 236,\n",
       " 'must': 237,\n",
       " 'r': 238,\n",
       " 'move': 239,\n",
       " 'book': 240,\n",
       " 'aww': 241,\n",
       " 'die': 242,\n",
       " 'busi': 243,\n",
       " 'com': 244,\n",
       " 'gone': 245,\n",
       " 'boy': 246,\n",
       " 'may': 247,\n",
       " 'anyth': 248,\n",
       " 'shop': 249,\n",
       " 'buy': 250,\n",
       " 'famili': 251,\n",
       " 'woke': 252,\n",
       " 'studi': 253,\n",
       " 'plan': 254,\n",
       " 'hair': 255,\n",
       " 'total': 256,\n",
       " 'food': 257,\n",
       " 'least': 258,\n",
       " 'okay': 259,\n",
       " 'almost': 260,\n",
       " 'lunch': 261,\n",
       " 'month': 262,\n",
       " 'cute': 263,\n",
       " 'till': 264,\n",
       " 'tho': 265,\n",
       " 'iphon': 266,\n",
       " 'free': 267,\n",
       " 'drink': 268,\n",
       " 'dinner': 269,\n",
       " 'sweet': 270,\n",
       " 'far': 271,\n",
       " 'caus': 272,\n",
       " 'believ': 273,\n",
       " 'pictur': 274,\n",
       " '10': 275,\n",
       " 'shit': 276,\n",
       " 'funni': 277,\n",
       " 'win': 278,\n",
       " 'everyth': 279,\n",
       " 'place': 280,\n",
       " 'chang': 281,\n",
       " 'class': 282,\n",
       " 'welcom': 283,\n",
       " 'anyon': 284,\n",
       " 'gt': 285,\n",
       " 'drive': 286,\n",
       " 'turn': 287,\n",
       " 'sit': 288,\n",
       " 'mine': 289,\n",
       " 'forward': 290,\n",
       " 'ask': 291,\n",
       " '6': 292,\n",
       " 'without': 293,\n",
       " 'name': 294,\n",
       " 'walk': 295,\n",
       " 'stupid': 296,\n",
       " 'write': 297,\n",
       " 'dream': 298,\n",
       " 'idea': 299,\n",
       " 'real': 300,\n",
       " 'hahaha': 301,\n",
       " 'send': 302,\n",
       " 'outsid': 303,\n",
       " 'clean': 304,\n",
       " 'dad': 305,\n",
       " 'coffe': 306,\n",
       " 'ill': 307,\n",
       " 'enough': 308,\n",
       " 'room': 309,\n",
       " 'dog': 310,\n",
       " 'anymor': 311,\n",
       " 'wrong': 312,\n",
       " 'probabl': 313,\n",
       " 'p': 314,\n",
       " 'everi': 315,\n",
       " 'wake': 316,\n",
       " 'didnt': 317,\n",
       " 'fan': 318,\n",
       " 'saturday': 319,\n",
       " 'tv': 320,\n",
       " 'ha': 321,\n",
       " 'money': 322,\n",
       " 'minut': 323,\n",
       " 'c': 324,\n",
       " 'repli': 325,\n",
       " 'xx': 326,\n",
       " 'break': 327,\n",
       " 'person': 328,\n",
       " 'rememb': 329,\n",
       " 'eye': 330,\n",
       " 'serious': 331,\n",
       " 'face': 332,\n",
       " 'headach': 333,\n",
       " 'sooo': 334,\n",
       " 'aw': 335,\n",
       " 'rock': 336,\n",
       " 'hit': 337,\n",
       " 'brother': 338,\n",
       " '30': 339,\n",
       " 'fail': 340,\n",
       " '8': 341,\n",
       " 'beach': 342,\n",
       " 'blog': 343,\n",
       " 'train': 344,\n",
       " 'whole': 345,\n",
       " 'seen': 346,\n",
       " 'came': 347,\n",
       " 'open': 348,\n",
       " 'kinda': 349,\n",
       " 'hang': 350,\n",
       " 'crazi': 351,\n",
       " 'rest': 352,\n",
       " '7': 353,\n",
       " 'mother': 354,\n",
       " 'kill': 355,\n",
       " 'pain': 356,\n",
       " 'close': 357,\n",
       " 'word': 358,\n",
       " 'comput': 359,\n",
       " 'took': 360,\n",
       " 'super': 361,\n",
       " 'care': 362,\n",
       " 'quit': 363,\n",
       " 'hell': 364,\n",
       " 'half': 365,\n",
       " 'text': 366,\n",
       " 'hello': 367,\n",
       " 'news': 368,\n",
       " 'worri': 369,\n",
       " 'anyway': 370,\n",
       " 'awww': 371,\n",
       " 'true': 372,\n",
       " 'goodnight': 373,\n",
       " 'heart': 374,\n",
       " 'part': 375,\n",
       " 'trip': 376,\n",
       " 'forgot': 377,\n",
       " 'problem': 378,\n",
       " 'abl': 379,\n",
       " 'els': 380,\n",
       " 'bring': 381,\n",
       " 'ago': 382,\n",
       " 'kind': 383,\n",
       " 'either': 384,\n",
       " 'mind': 385,\n",
       " 'offic': 386,\n",
       " 'photo': 387,\n",
       " 'full': 388,\n",
       " 'link': 389,\n",
       " 'boo': 390,\n",
       " 'pay': 391,\n",
       " 'ah': 392,\n",
       " 'soo': 393,\n",
       " 'danc': 394,\n",
       " 'hug': 395,\n",
       " 'cuz': 396,\n",
       " 'sister': 397,\n",
       " 'internet': 398,\n",
       " 'alon': 399,\n",
       " 'stuck': 400,\n",
       " 'hehe': 401,\n",
       " 'test': 402,\n",
       " 'fall': 403,\n",
       " 'btw': 404,\n",
       " 'heard': 405,\n",
       " 'cours': 406,\n",
       " 'sometim': 407,\n",
       " 'email': 408,\n",
       " 'ticket': 409,\n",
       " 'pick': 410,\n",
       " 'site': 411,\n",
       " 'www': 412,\n",
       " 'learn': 413,\n",
       " 'interest': 414,\n",
       " 'set': 415,\n",
       " 'shower': 416,\n",
       " 'concert': 417,\n",
       " 'hand': 418,\n",
       " 'vote': 419,\n",
       " 'add': 420,\n",
       " 'wont': 421,\n",
       " 'pass': 422,\n",
       " 'dude': 423,\n",
       " 'season': 424,\n",
       " 'awak': 425,\n",
       " 'suppos': 426,\n",
       " 'fine': 427,\n",
       " 'onlin': 428,\n",
       " 'visit': 429,\n",
       " 'ice': 430,\n",
       " 'breakfast': 431,\n",
       " 'facebook': 432,\n",
       " 'told': 433,\n",
       " 'cat': 434,\n",
       " 'fix': 435,\n",
       " 'goe': 436,\n",
       " 'favorit': 437,\n",
       " 'sunni': 438,\n",
       " 'ass': 439,\n",
       " 'til': 440,\n",
       " 'pack': 441,\n",
       " 'catch': 442,\n",
       " 'smile': 443,\n",
       " 'cut': 444,\n",
       " 'broke': 445,\n",
       " 'wear': 446,\n",
       " 'high': 447,\n",
       " 'spend': 448,\n",
       " 'lucki': 449,\n",
       " 'crap': 450,\n",
       " 'bought': 451,\n",
       " 'lmao': 452,\n",
       " 'hungri': 453,\n",
       " 'afternoon': 454,\n",
       " 'asleep': 455,\n",
       " 'june': 456,\n",
       " 'la': 457,\n",
       " 'reason': 458,\n",
       " '9': 459,\n",
       " 'mad': 460,\n",
       " 'ladi': 461,\n",
       " 'ride': 462,\n",
       " 'definit': 463,\n",
       " 'red': 464,\n",
       " '100': 465,\n",
       " 'agre': 466,\n",
       " 'laugh': 467,\n",
       " 'sign': 468,\n",
       " 'xd': 469,\n",
       " 'yea': 470,\n",
       " 'instead': 471,\n",
       " 'bye': 472,\n",
       " 'perfect': 473,\n",
       " 'short': 474,\n",
       " 'sigh': 475,\n",
       " 'jealous': 476,\n",
       " 'sore': 477,\n",
       " 'e': 478,\n",
       " 'homework': 479,\n",
       " 'bout': 480,\n",
       " 'stori': 481,\n",
       " 'wed': 482,\n",
       " 'top': 483,\n",
       " 'nap': 484,\n",
       " 'second': 485,\n",
       " 'citi': 486,\n",
       " 'album': 487,\n",
       " 'page': 488,\n",
       " 'dear': 489,\n",
       " 'messag': 490,\n",
       " 'nite': 491,\n",
       " 'list': 492,\n",
       " 'graduat': 493,\n",
       " 'figur': 494,\n",
       " 'togeth': 495,\n",
       " 'tour': 496,\n",
       " 'dead': 497,\n",
       " 'near': 498,\n",
       " 'join': 499,\n",
       " '0': 500,\n",
       " 'sing': 501,\n",
       " 'date': 502,\n",
       " 'holiday': 503,\n",
       " 'store': 504,\n",
       " 'congrat': 505,\n",
       " 'laptop': 506,\n",
       " 'park': 507,\n",
       " 'soooo': 508,\n",
       " 'youtub': 509,\n",
       " 'l': 510,\n",
       " 'save': 511,\n",
       " 'star': 512,\n",
       " 'complet': 513,\n",
       " 'coupl': 514,\n",
       " 'moment': 515,\n",
       " '12': 516,\n",
       " 'award': 517,\n",
       " 'water': 518,\n",
       " 'revis': 519,\n",
       " 'line': 520,\n",
       " 'point': 521,\n",
       " 'goin': 522,\n",
       " 'relax': 523,\n",
       " 'drop': 524,\n",
       " 'side': 525,\n",
       " 'town': 526,\n",
       " 'tea': 527,\n",
       " 'order': 528,\n",
       " 'annoy': 529,\n",
       " 'ipod': 530,\n",
       " 'church': 531,\n",
       " 'dress': 532,\n",
       " 'weird': 533,\n",
       " 'answer': 534,\n",
       " 'cook': 535,\n",
       " 'download': 536,\n",
       " 'less': 537,\n",
       " 'ppl': 538,\n",
       " 'account': 539,\n",
       " 'ive': 540,\n",
       " 'decid': 541,\n",
       " 'cream': 542,\n",
       " '20': 543,\n",
       " 'share': 544,\n",
       " 'forget': 545,\n",
       " 'offici': 546,\n",
       " 'mood': 547,\n",
       " 'gym': 548,\n",
       " 'scare': 549,\n",
       " 'lose': 550,\n",
       " 'realiz': 551,\n",
       " 'air': 552,\n",
       " 'lil': 553,\n",
       " 'min': 554,\n",
       " 'chat': 555,\n",
       " 'math': 556,\n",
       " 'english': 557,\n",
       " 'understand': 558,\n",
       " 'fli': 559,\n",
       " 'past': 560,\n",
       " 'usual': 561,\n",
       " 'band': 562,\n",
       " 'chocol': 563,\n",
       " 'mum': 564,\n",
       " 'unfortun': 565,\n",
       " 'fb': 566,\n",
       " 'episod': 567,\n",
       " 'comment': 568,\n",
       " 'differ': 569,\n",
       " 'fast': 570,\n",
       " 'knew': 571,\n",
       " 'ate': 572,\n",
       " 'pool': 573,\n",
       " '11': 574,\n",
       " 'worst': 575,\n",
       " 'ahh': 576,\n",
       " 'upload': 577,\n",
       " 'load': 578,\n",
       " 'window': 579,\n",
       " 'kick': 580,\n",
       " 'broken': 581,\n",
       " 'london': 582,\n",
       " 'chanc': 583,\n",
       " 'team': 584,\n",
       " 'hmm': 585,\n",
       " 'cheer': 586,\n",
       " 'parent': 587,\n",
       " 'support': 588,\n",
       " 'black': 589,\n",
       " 'yep': 590,\n",
       " 'horribl': 591,\n",
       " 'question': 592,\n",
       " 'throat': 593,\n",
       " 'flight': 594,\n",
       " 'sat': 595,\n",
       " 'sleepi': 596,\n",
       " '1st': 597,\n",
       " 'via': 598,\n",
       " 'worth': 599,\n",
       " 'myspac': 600,\n",
       " 'xxx': 601,\n",
       " 'card': 602,\n",
       " 'special': 603,\n",
       " 'three': 604,\n",
       " 'upset': 605,\n",
       " 'slow': 606,\n",
       " 'sunshin': 607,\n",
       " 'depress': 608,\n",
       " 'leg': 609,\n",
       " 'fair': 610,\n",
       " 'bless': 611,\n",
       " 'mac': 612,\n",
       " 'green': 613,\n",
       " 'followfriday': 614,\n",
       " 'shirt': 615,\n",
       " 'jona': 616,\n",
       " 'beat': 617,\n",
       " 'da': 618,\n",
       " 'bet': 619,\n",
       " 'number': 620,\n",
       " 'em': 621,\n",
       " 'gave': 622,\n",
       " 'sent': 623,\n",
       " 'record': 624,\n",
       " 'k': 625,\n",
       " 'paper': 626,\n",
       " 'colleg': 627,\n",
       " 'cake': 628,\n",
       " 'tuesday': 629,\n",
       " 'ad': 630,\n",
       " 'g': 631,\n",
       " 'finger': 632,\n",
       " 'project': 633,\n",
       " '15': 634,\n",
       " 'app': 635,\n",
       " 'beer': 636,\n",
       " 'warm': 637,\n",
       " 'appar': 638,\n",
       " 'moon': 639,\n",
       " 'what': 640,\n",
       " 'vacat': 641,\n",
       " 'blue': 642,\n",
       " 'websit': 643,\n",
       " 'fell': 644,\n",
       " 'wors': 645,\n",
       " 'garden': 646,\n",
       " 'easi': 647,\n",
       " 'power': 648,\n",
       " 'doesnt': 649,\n",
       " 'bday': 650,\n",
       " 'rather': 651,\n",
       " 'disappoint': 652,\n",
       " 'light': 653,\n",
       " 'film': 654,\n",
       " 'possibl': 655,\n",
       " 'nope': 656,\n",
       " 'safe': 657,\n",
       " 'cannot': 658,\n",
       " 'huge': 659,\n",
       " 'longer': 660,\n",
       " 'juli': 661,\n",
       " 'bodi': 662,\n",
       " 'miley': 663,\n",
       " 'mess': 664,\n",
       " 'wtf': 665,\n",
       " 'shoe': 666,\n",
       " 'mr': 667,\n",
       " 'uk': 668,\n",
       " 'spent': 669,\n",
       " 'flu': 670,\n",
       " 'due': 671,\n",
       " 'googl': 672,\n",
       " 'voic': 673,\n",
       " 'cancel': 674,\n",
       " 'absolut': 675,\n",
       " 'lay': 676,\n",
       " 'shame': 677,\n",
       " 'freak': 678,\n",
       " 'celebr': 679,\n",
       " 'plus': 680,\n",
       " 'cousin': 681,\n",
       " 'bike': 682,\n",
       " 'sim': 683,\n",
       " 'mtv': 684,\n",
       " 'thx': 685,\n",
       " 'age': 686,\n",
       " 'chill': 687,\n",
       " 'earlier': 688,\n",
       " 'ahhh': 689,\n",
       " 'stress': 690,\n",
       " 'lazi': 691,\n",
       " 'white': 692,\n",
       " 'babe': 693,\n",
       " 'quick': 694,\n",
       " 'burn': 695,\n",
       " 'touch': 696,\n",
       " 'swim': 697,\n",
       " 'hold': 698,\n",
       " 'remind': 699,\n",
       " 'forev': 700,\n",
       " 'thursday': 701,\n",
       " 'lie': 702,\n",
       " 'box': 703,\n",
       " 'stomach': 704,\n",
       " 'except': 705,\n",
       " 'especi': 706,\n",
       " 'bus': 707,\n",
       " 'david': 708,\n",
       " 'camera': 709,\n",
       " 'shot': 710,\n",
       " 'camp': 711,\n",
       " 'manag': 712,\n",
       " 'exact': 713,\n",
       " 'pray': 714,\n",
       " 'son': 715,\n",
       " 'v': 716,\n",
       " 'appreci': 717,\n",
       " 'idk': 718,\n",
       " 'slept': 719,\n",
       " 'tom': 720,\n",
       " 'boyfriend': 721,\n",
       " 'met': 722,\n",
       " 'bum': 723,\n",
       " 'insid': 724,\n",
       " 'appl': 725,\n",
       " 'type': 726,\n",
       " 'crash': 727,\n",
       " 'surpris': 728,\n",
       " 'sort': 729,\n",
       " 'piss': 730,\n",
       " 'present': 731,\n",
       " 'fight': 732,\n",
       " 'current': 733,\n",
       " 'note': 734,\n",
       " 'havent': 735,\n",
       " 'yummi': 736,\n",
       " 'airport': 737,\n",
       " 'wit': 738,\n",
       " 'mail': 739,\n",
       " 'arriv': 740,\n",
       " 'servic': 741,\n",
       " 'shoot': 742,\n",
       " 'random': 743,\n",
       " 'luv': 744,\n",
       " 'block': 745,\n",
       " 'bitch': 746,\n",
       " 'confus': 747,\n",
       " 'terribl': 748,\n",
       " 'road': 749,\n",
       " 'cover': 750,\n",
       " 'invit': 751,\n",
       " 'pizza': 752,\n",
       " 'hospit': 753,\n",
       " 'father': 754,\n",
       " 'small': 755,\n",
       " 'bbq': 756,\n",
       " 'club': 757,\n",
       " 'meant': 758,\n",
       " 'interview': 759,\n",
       " 'fit': 760,\n",
       " 'expect': 761,\n",
       " '2day': 762,\n",
       " 'cloth': 763,\n",
       " 'tast': 764,\n",
       " 'dm': 765,\n",
       " 'count': 766,\n",
       " 'case': 767,\n",
       " 'hill': 768,\n",
       " 'radio': 769,\n",
       " 'doctor': 770,\n",
       " 'chicken': 771,\n",
       " 'alright': 772,\n",
       " 'hubbi': 773,\n",
       " 'storm': 774,\n",
       " 'proud': 775,\n",
       " 'deal': 776,\n",
       " 'design': 777,\n",
       " 'f': 778,\n",
       " 'mention': 779,\n",
       " 'raini': 780,\n",
       " 'twilight': 781,\n",
       " 'tummi': 782,\n",
       " 'smell': 783,\n",
       " 'felt': 784,\n",
       " 'stand': 785,\n",
       " 'lone': 786,\n",
       " 'shall': 787,\n",
       " 'notic': 788,\n",
       " 'cup': 789,\n",
       " 'speak': 790,\n",
       " 'wine': 791,\n",
       " 'goodby': 792,\n",
       " 'begin': 793,\n",
       " 'laker': 794,\n",
       " 'search': 795,\n",
       " 'cd': 796,\n",
       " 'bag': 797,\n",
       " 'gorgeous': 798,\n",
       " 'peac': 799,\n",
       " 'ach': 800,\n",
       " 'addict': 801,\n",
       " 'lame': 802,\n",
       " 'feet': 803,\n",
       " 'fact': 804,\n",
       " 'pull': 805,\n",
       " 'wednesday': 806,\n",
       " 'wash': 807,\n",
       " 'hmmm': 808,\n",
       " 'practic': 809,\n",
       " 'yup': 810,\n",
       " 'bar': 811,\n",
       " 'issu': 812,\n",
       " 'kiss': 813,\n",
       " 'front': 814,\n",
       " 'product': 815,\n",
       " 'tan': 816,\n",
       " 'connect': 817,\n",
       " 'woo': 818,\n",
       " 'cos': 819,\n",
       " 'glass': 820,\n",
       " 'compani': 821,\n",
       " 'xoxo': 822,\n",
       " 'whatev': 823,\n",
       " 'roll': 824,\n",
       " 'memori': 825,\n",
       " 'state': 826,\n",
       " 'ouch': 827,\n",
       " 'tear': 828,\n",
       " 'ball': 829,\n",
       " 'event': 830,\n",
       " 'taken': 831,\n",
       " 'scari': 832,\n",
       " 'french': 833,\n",
       " 'round': 834,\n",
       " 'exhaust': 835,\n",
       " 'paint': 836,\n",
       " 'drunk': 837,\n",
       " 'joke': 838,\n",
       " 'bro': 839,\n",
       " 'apart': 840,\n",
       " 'mate': 841,\n",
       " 'jus': 842,\n",
       " 'normal': 843,\n",
       " 'behind': 844,\n",
       " 'daughter': 845,\n",
       " 'becom': 846,\n",
       " 'travel': 847,\n",
       " 'mile': 848,\n",
       " '2nd': 849,\n",
       " 'gettin': 850,\n",
       " 'fire': 851,\n",
       " 'door': 852,\n",
       " 'ear': 853,\n",
       " 'isnt': 854,\n",
       " 'guitar': 855,\n",
       " 'prob': 856,\n",
       " 'everybodi': 857,\n",
       " 'plane': 858,\n",
       " 'puppi': 859,\n",
       " 'singl': 860,\n",
       " 'wife': 861,\n",
       " 'version': 862,\n",
       " 'releas': 863,\n",
       " 'yo': 864,\n",
       " 'j': 865,\n",
       " 'rip': 866,\n",
       " 'sold': 867,\n",
       " 'return': 868,\n",
       " 'sell': 869,\n",
       " 'cross': 870,\n",
       " 'matter': 871,\n",
       " 'vega': 872,\n",
       " 'pop': 873,\n",
       " 'mommi': 874,\n",
       " 'promis': 875,\n",
       " 'arm': 876,\n",
       " 'hangov': 877,\n",
       " 'sis': 878,\n",
       " 'allow': 879,\n",
       " 'fantast': 880,\n",
       " 'fri': 881,\n",
       " 'hahah': 882,\n",
       " 'art': 883,\n",
       " 'web': 884,\n",
       " 'sale': 885,\n",
       " 'magic': 886,\n",
       " 'although': 887,\n",
       " 'alot': 888,\n",
       " 'wat': 889,\n",
       " 'fish': 890,\n",
       " 'clear': 891,\n",
       " 'countri': 892,\n",
       " 'self': 893,\n",
       " 'along': 894,\n",
       " 'bug': 895,\n",
       " 'dark': 896,\n",
       " 'ruin': 897,\n",
       " 'cooki': 898,\n",
       " 'hotel': 899,\n",
       " 'death': 900,\n",
       " 'screen': 901,\n",
       " 'group': 902,\n",
       " 'track': 903,\n",
       " 'nick': 904,\n",
       " 'hun': 905,\n",
       " 'wast': 906,\n",
       " 'inde': 907,\n",
       " 'histori': 908,\n",
       " 'act': 909,\n",
       " 'perform': 910,\n",
       " 'ahead': 911,\n",
       " 'aint': 912,\n",
       " 'gosh': 913,\n",
       " 'huh': 914,\n",
       " 'eh': 915,\n",
       " 'instal': 916,\n",
       " 'bird': 917,\n",
       " 'profil': 918,\n",
       " 'deserv': 919,\n",
       " 'buddi': 920,\n",
       " 'ohh': 921,\n",
       " 'twit': 922,\n",
       " 'cough': 923,\n",
       " 'low': 924,\n",
       " 'vip': 925,\n",
       " 'nobodi': 926,\n",
       " 'heat': 927,\n",
       " 'fill': 928,\n",
       " 'grow': 929,\n",
       " 'fml': 930,\n",
       " 'extra': 931,\n",
       " 'angel': 932,\n",
       " 'sexi': 933,\n",
       " 'fat': 934,\n",
       " 'posit': 935,\n",
       " 'yum': 936,\n",
       " 'blood': 937,\n",
       " 'dvd': 938,\n",
       " 'land': 939,\n",
       " 'pink': 940,\n",
       " 'race': 941,\n",
       " 'major': 942,\n",
       " 'troubl': 943,\n",
       " 'bloodi': 944,\n",
       " 'chees': 945,\n",
       " 'traffic': 946,\n",
       " 'street': 947,\n",
       " 'throw': 948,\n",
       " 'gut': 949,\n",
       " 'delet': 950,\n",
       " 'daddi': 951,\n",
       " 'men': 952,\n",
       " 'nail': 953,\n",
       " 'gay': 954,\n",
       " 'somewher': 955,\n",
       " 'ran': 956,\n",
       " 'dunno': 957,\n",
       " 'vid': 958,\n",
       " 'edit': 959,\n",
       " 'bb': 960,\n",
       " '24': 961,\n",
       " 'nose': 962,\n",
       " 'dang': 963,\n",
       " 'coz': 964,\n",
       " 'itun': 965,\n",
       " '50': 966,\n",
       " 'caught': 967,\n",
       " 'other': 968,\n",
       " 'view': 969,\n",
       " 'ff': 970,\n",
       " 'shut': 971,\n",
       " 'prepar': 972,\n",
       " 'pc': 973,\n",
       " 'recommend': 974,\n",
       " 'fever': 975,\n",
       " 'ooh': 976,\n",
       " 'step': 977,\n",
       " 'suggest': 978,\n",
       " 'fam': 979,\n",
       " 'result': 980,\n",
       " 'tweetdeck': 981,\n",
       " 'watchin': 982,\n",
       " 'bill': 983,\n",
       " 'awwww': 984,\n",
       " 'shine': 985,\n",
       " 'blah': 986,\n",
       " 'inspir': 987,\n",
       " 'direct': 988,\n",
       " 'nyc': 989,\n",
       " 'chillin': 990,\n",
       " 'market': 991,\n",
       " 'congratul': 992,\n",
       " 'taylor': 993,\n",
       " 'def': 994,\n",
       " 'report': 995,\n",
       " 'hrs': 996,\n",
       " 'doubt': 997,\n",
       " 'mall': 998,\n",
       " 'brain': 999,\n",
       " 'choic': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "41467aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word = tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "756435fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248632"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(word_index)+1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "96487874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6891e8d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tokenizer.to_json() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [101]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizer.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Tokenizer.to_json() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "tokenizer.to_json(\"tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "79824d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50000\n",
    "max_len = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "53b40b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenizer.texts_to_sequences(train_data['text'])\n",
    "x_test = tokenizer.texts_to_sequences(test_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4241e733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yay happi job also mean less time'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['text'][45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "35d647a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[313, 67, 65, 33, 53, 3526, 1503, 6549, 128, 4, 197, 44797, 1400]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f8d5d9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "691236ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = pad_sequences(x_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1820ecaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,   313,\n",
       "          67,    65,    33,    53,  3526,  1503,  6549,   128,     4,\n",
       "         197, 44797,  1400], dtype=int32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c6d0e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['target'].values\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "y_test = test_data['target'].values\n",
    "y_test = y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b3badb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c3622bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280000, 1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c682a6",
   "metadata": {},
   "source": [
    "# Text Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f6251d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7cae72ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c247b0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.953487812212206"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(vocab_size, 1/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c12ed150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 21:42:54.266695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 21:42:54.327874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 21:42:54.328061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 21:42:54.331093: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-05 21:42:54.331966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 21:42:54.332119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 21:42:54.332253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 21:42:54.956021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 21:42:54.956229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 21:42:54.956409: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 21:42:54.956771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6088 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.\n",
    "    tf.keras.layers.Embedding(vocab_size, 15),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(15)),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "29e665e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate=0.00001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "88310d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3564468e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 15)          750000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 30)               3720      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                620       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 754,361\n",
      "Trainable params: 754,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d63d39f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 21:46:13.582142: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 153600000 exceeds 10% of free system memory.\n",
      "2023-06-05 21:46:17.185014: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8500\n",
      "2023-06-05 21:46:17.353367: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6916 - accuracy: 0.5801"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 21:46:25.075067: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 38400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 13s 7ms/step - loss: 0.6916 - accuracy: 0.5803 - val_loss: 0.6895 - val_accuracy: 0.6305\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.6849 - accuracy: 0.6584 - val_loss: 0.6782 - val_accuracy: 0.6818\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.6658 - accuracy: 0.6975 - val_loss: 0.6501 - val_accuracy: 0.7123\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.6280 - accuracy: 0.7215 - val_loss: 0.6056 - val_accuracy: 0.7288\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.5860 - accuracy: 0.7337 - val_loss: 0.5714 - val_accuracy: 0.7380\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.5598 - accuracy: 0.7429 - val_loss: 0.5523 - val_accuracy: 0.7453\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.5434 - accuracy: 0.7493 - val_loss: 0.5387 - val_accuracy: 0.7503\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.5303 - accuracy: 0.7545 - val_loss: 0.5269 - val_accuracy: 0.7550\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.5190 - accuracy: 0.7587 - val_loss: 0.5167 - val_accuracy: 0.7583\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.5092 - accuracy: 0.7624 - val_loss: 0.5081 - val_accuracy: 0.7616\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.5010 - accuracy: 0.7653 - val_loss: 0.5010 - val_accuracy: 0.7640\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.4940 - accuracy: 0.7677 - val_loss: 0.4949 - val_accuracy: 0.7659\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.4880 - accuracy: 0.7698 - val_loss: 0.4900 - val_accuracy: 0.7676\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.4833 - accuracy: 0.7715 - val_loss: 0.4864 - val_accuracy: 0.7687\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.4798 - accuracy: 0.7730 - val_loss: 0.4838 - val_accuracy: 0.7701\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.4771 - accuracy: 0.7744 - val_loss: 0.4818 - val_accuracy: 0.7712\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.4749 - accuracy: 0.7757 - val_loss: 0.4802 - val_accuracy: 0.7718\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.4729 - accuracy: 0.7768 - val_loss: 0.4788 - val_accuracy: 0.7728\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.4712 - accuracy: 0.7778 - val_loss: 0.4776 - val_accuracy: 0.7733\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.4696 - accuracy: 0.7786 - val_loss: 0.4765 - val_accuracy: 0.7736\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=1024, \n",
    "                    epochs=20, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b9c504d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "77a7b5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b1ca3fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6e8503a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 15)          750000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 30)               3720      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                620       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 754,361\n",
      "Trainable params: 754,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "saved_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "019546b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Twilight didn't come yesterday  fingers crossed for today\""
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'][455]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "25a14471",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = \"@Twilight didn't come yesterday  fingers crossed for today I loved this class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b2cdb8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'come yesterday finger cross today love class'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nettoyage(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "33beb37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38, 211, 632, 870, 9, 7, 282]]\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "tweet = nettoyage(tweet)\n",
    "#print(tweet)\n",
    "tweet = tokenizer.texts_to_sequences([tweet])\n",
    "print(tweet)\n",
    "tweet = pad_sequences(tweet, maxlen=30)\n",
    "result = saved_model.predict([tweet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "25a50839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.43274855613708"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.item() *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c813440e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
